Application of LLMs - 
  1.) Using open source models for sentence/paragraph embedding.
  2.) Document loading using chunks and then embedding it and storing in a vector DB.(Set-ip a vector DB for the same)
  3.) Using a pre-trained model for propmt answering/question-answering usecases.
  4.) RAG AGents, how to scale that up?
  5.) Try exploring different aspects of prompt engineering as in how can we make sure that our model does not hallucinates, what is quantization, how it is done, what are its different types.(GPC/GPCI similar)
  6.) Fine Tuning LLMs
  7.) Vision transformers
  8.) Theory - Transformers architecture, self attention and vision transformers.
